{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Generate Figure 4\n",
    "Population activity in neuronal pattern space, shows that different neuronal \n",
    "assemblies are active for each population activity trajectories. A. Smoothed \n",
    "single neuron activity for 0.5 sec of stimulus (green area) and 0.5 sec of \n",
    "delay epoch. B. Same population activity as in A, but now reduced with NNMF \n",
    "to 3 components (assembly space). The dynamic and highly irregular single \n",
    "neuron activity, appears smooth in the assembly space. Also the change from \n",
    "the stimulus to delay epoch is evident. C. Activity of 7 trials with delay \n",
    "epoch response (out of 10), colored as three k-means identified states, \n",
    "presented each time with respect to an assembly activity. It is evident \n",
    "that stable population states that cluster in state space (similar colors), \n",
    "appear to correspond to activity of a specific assembly. D. Same data as C, \n",
    "now plotted in assembly space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import notebook_module as nb\n",
    "import analysis_tools as analysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pynwb import NWBHDF5IO\n",
    "from itertools import chain\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import scipy.stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simulations_dir = Path.cwd().joinpath('simulations')\n",
    "data_dir = Path.cwd().joinpath('crossvalidation_errors')\n",
    "plt.rcParams.update({'font.family': 'Helvetica'})\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 15)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "no_of_conditions = 10\n",
    "no_of_animals = 4\n",
    "dataset_name = lambda x : f'Network {x}'\n",
    "\n",
    "simulations_dir = Path.cwd().joinpath('simulations')\n",
    "plt.rcParams.update({'font.family': 'Helvetica'})\n",
    "#===============================================================================\n",
    "#===============================================================================\n",
    "# Beginning of Figure 4\n",
    "#===============================================================================\n",
    "#===============================================================================\n",
    "plt.ion()\n",
    "\n",
    "# I must discover the optimal number of NNMF components:\n",
    "#fig, axblah = plt.subplots(1,1)\n",
    "#plt.cla()\n",
    "#plt.ion()\n",
    "\n",
    "subplot_width = 4\n",
    "subplot_height = 1\n",
    "figure4 = plt.figure(figsize=plt.figaspect(subplot_height / subplot_width))\n",
    "\n",
    "gs1 = gridspec.GridSpec(\n",
    "    1, 1, left=0.05, right=0.15, top=0.95, bottom=0.50, wspace=0.35, hspace=0.0\n",
    ")\n",
    "A_axis_a = plt.subplot(gs1[:, 0])\n",
    "\n",
    "gs1b = gridspec.GridSpec(\n",
    "    3, 1, left=0.05, right=0.15, top=0.40, bottom=0.15, wspace=0.35, hspace=0.0\n",
    ")\n",
    "B_axis_a = plt.subplot(gs1b[0, 0])\n",
    "B_axis_b = plt.subplot(gs1b[1, 0])\n",
    "B_axis_c = plt.subplot(gs1b[2, 0])\n",
    "\n",
    "gs2 = gridspec.GridSpec(\n",
    "    3, 1, left=0.25, right=0.50, top=0.95, bottom=0.15, wspace=0.35, hspace=0.2\n",
    ")\n",
    "C_axis_a = plt.subplot(gs2[0, 0])\n",
    "C_axis_b = plt.subplot(gs2[1, 0])\n",
    "C_axis_c = plt.subplot(gs2[2, 0])\n",
    "nb.mark_figure_letter(C_axis_a, 'C')\n",
    "\n",
    "# Plot same animal model, different learning conditions:\n",
    "NWBfile = analysis.load_nwb_file(\n",
    "    animal_model=3,\n",
    "    learning_condition=3,\n",
    "    experiment_config='structured',\n",
    "    type='bn',\n",
    "    data_path=simulations_dir\n",
    ")\n",
    "\n",
    "trial_len = analysis.get_acquisition_parameters(\n",
    "    input_NWBfile=NWBfile,\n",
    "    requested_parameters=['trial_len']\n",
    ")\n",
    "custom_range = (20, int(trial_len / 50))\n",
    "\n",
    "K_star, K_labels, BIC_val, _ = analysis.determine_number_of_clusters(\n",
    "    NWBfile_array=[NWBfile],\n",
    "    max_clusters=10,\n",
    "    custom_range=custom_range\n",
    ")\n",
    "\n",
    "# Dynamic network response:\n",
    "trial_inst_ff = analysis.trial_instantaneous_frequencies(\n",
    "    NWBfile=NWBfile, trialid=1, smooth=True\n",
    ")\n",
    "ff_threshold = 5  # Hz\n",
    "A_axis_a.cla()\n",
    "for cellid, inst_ff in trial_inst_ff:\n",
    "    #if inst_ff.mean() > ff_threshold:\n",
    "    A_axis_a.plot(inst_ff[550:1550])\n",
    "A_axis_a.margins(0.0)\n",
    "A_axis_a.axvspan(0.0, 500.0, ymin=0, ymax=1, color='g', alpha=0.2)\n",
    "nb.adjust_spines(A_axis_a, ['left', 'bottom'])\n",
    "A_axis_a.xaxis.set_ticks_position('none')\n",
    "A_axis_a.xaxis.set_ticklabels([])\n",
    "nb.mark_figure_letter(A_axis_a, 'a')\n",
    "\n",
    "# First decomposition: stimulus to delay transition:\n",
    "W_stim2delay, *_ = analysis.NNMF(\n",
    "    NWBfile_array=[NWBfile],\n",
    "    n_components=3,\n",
    "    custom_range=(10, 30),\n",
    "    smooth=True,\n",
    "    plot=False\n",
    ")\n",
    "\n",
    "B_axis_a.plot(W_stim2delay[0,0,:].T, 'C0')\n",
    "B_axis_b.plot(W_stim2delay[1,0,:].T, 'C1')\n",
    "B_axis_c.plot(W_stim2delay[2,0,:].T, 'C2')\n",
    "B_axis_a.margins(0.0)\n",
    "B_axis_a.axvspan(0.0, 10.0, ymin=0, ymax=1, color='g', alpha=0.2)\n",
    "B_axis_a.xaxis.set_ticks_position('none')\n",
    "B_axis_a.xaxis.set_ticklabels([])\n",
    "B_axis_a.yaxis.set_ticks_position('none')\n",
    "B_axis_a.yaxis.set_ticklabels([])\n",
    "B_axis_b.margins(0.0)\n",
    "B_axis_b.axvspan(0.0, 10.0, ymin=0, ymax=1, color='g', alpha=0.2)\n",
    "B_axis_b.xaxis.set_ticks_position('none')\n",
    "B_axis_b.xaxis.set_ticklabels([])\n",
    "B_axis_b.yaxis.set_ticks_position('none')\n",
    "B_axis_b.yaxis.set_ticklabels([])\n",
    "B_axis_c.margins(0.0)\n",
    "B_axis_c.axvspan(0.0, 10.0, ymin=0, ymax=1, color='g', alpha=0.2)\n",
    "B_axis_c.xaxis.set_ticks_position('none')\n",
    "B_axis_c.xaxis.set_ticklabels([])\n",
    "B_axis_c.yaxis.set_ticks_position('none')\n",
    "B_axis_c.yaxis.set_ticklabels([])\n",
    "B_axis_c.set_xlabel('Time (ms)')\n",
    "nb.mark_figure_letter(B_axis_a, 'b')\n",
    "\n",
    "\n",
    "\n",
    "W_components, *_ = analysis.NNMF(\n",
    "    NWBfile_array=[NWBfile],\n",
    "    n_components=3,\n",
    "    custom_range=custom_range,\n",
    "    smooth=True,\n",
    "    plot=False\n",
    ")\n",
    "\n",
    "E_ax = [C_axis_a, C_axis_b, C_axis_c]\n",
    "klabels = K_labels\n",
    "# Color differently each trial:\n",
    "trial_colors = cm.Set2(np.linspace(0, 1, W_components.shape[1]))\n",
    "for assembly, assembly_axis in zip(range(1, 4), E_ax):\n",
    "    assembly_axis.cla()\n",
    "    for trialid in range(0, W_components.shape[1]):\n",
    "        #if klabels[trialid] == assembly:\n",
    "        # W components are normalized, but with the smoothing they exceed\n",
    "        # and they dont look good. So norm them again.\n",
    "        assembly_component = W_components[assembly - 1,trialid,:].T\n",
    "        assembly_axis.plot(assembly_component, color=trial_colors[trialid, :])\n",
    "    assembly_axis.set_ylabel(f'Assembly {assembly}\\nactivity')\n",
    "    assembly_axis.spines['top'].set_visible(False)\n",
    "    assembly_axis.spines['top'].set_color(None)\n",
    "    assembly_axis.spines['right'].set_visible(False)\n",
    "    assembly_axis.spines['right'].set_color(None)\n",
    "    assembly_axis.spines['left'].set_position('zero')\n",
    "    ylim = assembly_axis.get_ylim()\n",
    "    assembly_axis.set_yticks(ylim)\n",
    "    assembly_axis.set_yticklabels(['0', 'Max'])\n",
    "    nb.axis_normal_plot(assembly_axis)\n",
    "    nb.adjust_spines(assembly_axis, ['left'])\n",
    "    #assembly_axis.set_ylim([0.0, 1.1])\n",
    "    if assembly != 3:\n",
    "        assembly_axis.spines['bottom'].set_visible(False)\n",
    "        assembly_axis.spines['bottom'].set_color(None)\n",
    "        assembly_axis.tick_params(axis=False)\n",
    "        assembly_axis.xaxis.set_ticks_position('none')\n",
    "        assembly_axis.xaxis.set_ticklabels([])\n",
    "        assembly_axis.spines['bottom'].set_position('zero')\n",
    "\n",
    "C_axis_c.xaxis.set_ticks(range(0, 100, 20))\n",
    "C_axis_c.xaxis.set_ticklabels(range(0, 5))\n",
    "C_axis_c.set_xlabel('Time (sec)')\n",
    "C_axis_c.spines['bottom'].set_visible(True)\n",
    "C_axis_c.spines['bottom'].set_color('k')\n",
    "nb.adjust_spines(C_axis_c, ['left', 'bottom'])\n",
    "nb.mark_figure_letter(C_axis_a, 'c')\n",
    "\n",
    "\n",
    "#D_axis_b.set_xlim([0.0, 5000])\n",
    "#D_axis_b.set_ylim([0.0, 160])\n",
    "#D_axis_b.spines['left'].set_position('zero')\n",
    "#D_axis_b.spines['bottom'].set_position('zero')\n",
    "#D_axis_b.axvspan(50.0, 1050.0, ymin=0, ymax=1, color='g', alpha=0.2)\n",
    "\n",
    "gs3 = gridspec.GridSpec(\n",
    "    1, 1, left=0.55, right=0.75, top=0.95, bottom=0.15, wspace=0.35, hspace=0.2\n",
    ")\n",
    "D_axis_a = plt.subplot(gs3[0, 0], projection='3d')\n",
    "\n",
    "# A 3d plot with the last 1s of the above, in assemblie space.\n",
    "plot_axes = D_axis_a\n",
    "plot_axes.cla()\n",
    "# Stylize the 3d plot:\n",
    "plot_axes.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "plot_axes.w_yaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "plot_axes.w_zaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "plot_axes.set_xlabel('Assembly 1')\n",
    "plot_axes.set_ylabel('Assembly 2')\n",
    "plot_axes.set_zlabel('Assembly 3')\n",
    "#TODO: Someway the W_components are smaller (NNMF seems the culprit). Investigate\n",
    "pca_axis_limits = (0, 0.1)\n",
    "plot_axes.set_xlim(pca_axis_limits)\n",
    "plot_axes.set_ylim(pca_axis_limits)\n",
    "plot_axes.set_zlim(pca_axis_limits)\n",
    "plot_axes.set_xticks(pca_axis_limits)\n",
    "plot_axes.set_yticks(pca_axis_limits)\n",
    "plot_axes.set_zticks(pca_axis_limits)\n",
    "#azim, elev = plot_axes.azim, plot_axes.elev\n",
    "plot_axes.elev = 35#22.5\n",
    "plot_axes.azim = 45#52.4\n",
    "\n",
    "labels = klabels.tolist()\n",
    "nclusters = np.unique(klabels).size\n",
    "#colors = cm.Set2(np.linspace(0, 1, nclusters))\n",
    "_, key_labels = np.unique(labels, return_index=True)\n",
    "handles = []\n",
    "total_trials = W_components.shape[1]\n",
    "duration = W_components.shape[2]\n",
    "colors = {1: cm.Greens(np.linspace(0, 1, duration - 1)),\n",
    "          2: cm.Blues(np.linspace(0, 1, duration - 1)),\n",
    "          3: cm.Oranges(np.linspace(0, 1, duration - 1)),\n",
    "          }\n",
    "for i, (trial, label) in enumerate(zip(range(total_trials), labels)):\n",
    "    capture_artist = True\n",
    "    for t, c in zip(reversed(range(duration - 1)), reversed(colors[label])):\n",
    "        x = W_components[0][trial][t:t + 2]\n",
    "        y = W_components[1][trial][t:t + 2]\n",
    "        z = W_components[2][trial][t:t + 2]\n",
    "        handle = plot_axes.plot(x, y, z,\n",
    "                                color=c,\n",
    "                                label=f'State {label}'\n",
    "                                )\n",
    "        if t < duration / 2:\n",
    "            if i in key_labels and capture_artist:\n",
    "                print(t)\n",
    "                handles.append(handle[0])\n",
    "                capture_artist = False\n",
    "# Youmust group handles based on unique labels.\n",
    "plot_axes.legend(handles=handles, labels=['State 1', 'State 2', 'State 3'])\n",
    "nb.mark_figure_letter(D_axis_a, 'd')\n",
    "\n",
    "#TODO: na pros8eseis ena graph. h timh sto text pou na leei to cosine dist\n",
    "# aftwn twn vectors.\n",
    "\n",
    "gs4 = gridspec.GridSpec(\n",
    "    1, 1, left=0.80, right=0.95, top=0.95, bottom=0.15, wspace=0.35, hspace=0.2\n",
    ")\n",
    "E_axis_a = plt.subplot(gs4[0, 0])\n",
    "\n",
    "K_star_mat = np.zeros((no_of_animals, no_of_conditions), dtype=int)\n",
    "for animal_model in range(1, no_of_animals + 1):\n",
    "    for learning_condition in range(1, no_of_conditions + 1):\n",
    "        print(f'NT:{animal_model}, LC:{learning_condition}')\n",
    "        inputfile = data_dir.joinpath(\n",
    "            f'cross_valid_errors_structured{animal_model}_{learning_condition}.hdf'\n",
    "        )\n",
    "        # Read CV results.\n",
    "        try:\n",
    "            attribs = pd.read_hdf(inputfile, key='attributes').to_dict()\n",
    "            K = attribs['K'][0]\n",
    "            max_clusters = attribs['max_clusters'][0]\n",
    "            rng_max_iters = attribs['rng_max_iters'][0]\n",
    "            error_bar = pd.read_hdf(inputfile, key='error_bar') \\\n",
    "                .values.reshape(max_clusters, K, rng_max_iters) \\\n",
    "                    .mean(axis=2)\n",
    "            error_test = pd.read_hdf(inputfile, key='error_test') \\\n",
    "                .values.reshape(max_clusters, K, rng_max_iters) \\\n",
    "                    .mean(axis=2)\n",
    "            K_str_cv = np.argmin(error_test.mean(axis=1))\n",
    "            K_star_mat[animal_model - 1, learning_condition - 1] = K_str_cv\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Exception! {str(e)}')\n",
    "            pass\n",
    "\n",
    "# TODO: Plot number of clusters per animal/condition (na dw)\n",
    "# Run for every learning condition and animal the k-means clustering:\n",
    "optimal_clusters_of_group = defaultdict(partial(np.ndarray, 0))\n",
    "for animal_model in range(1, no_of_animals + 1):\n",
    "    # Pool together no of clusters for one animal model:\n",
    "    K_star_over_trials = np.ones((no_of_conditions, 2))\n",
    "    for learning_condition in range(1, no_of_conditions + 1):\n",
    "        # Lazy load the data as a NWB file. Easy to pass around and\n",
    "        # encapsulates info like trial length, stim times etc.\n",
    "        #TODO: this might raised some exceptions. Investigate!\n",
    "        nwbfile = analysis.load_nwb_file(\n",
    "            animal_model=animal_model,\n",
    "            learning_condition=learning_condition,\n",
    "            experiment_config='structured',\n",
    "            type='bn',\n",
    "            data_path=simulations_dir\n",
    "        )\n",
    "\n",
    "        trial_len = analysis.get_acquisition_parameters(\n",
    "            input_NWBfile=nwbfile,\n",
    "            requested_parameters=['trial_len']\n",
    "        )\n",
    "\n",
    "        # TODO: Where is custom range needed? determine a global way\n",
    "        # of passing it around...\n",
    "        custom_range = (20, int(trial_len / 50))\n",
    "\n",
    "        K_star, K_labels, BIC_val, _ = analysis.determine_number_of_clusters(\n",
    "            NWBfile_array=[nwbfile],\n",
    "            max_clusters=no_of_conditions,\n",
    "            custom_range=custom_range\n",
    "        )\n",
    "\n",
    "        K_star_over_trials[learning_condition - 1, :] = \\\n",
    "            [K_star, K_star_mat[animal_model-1][learning_condition-1]]\n",
    "\n",
    "    optimal_clusters_of_group[dataset_name(animal_model)] = \\\n",
    "        K_star_over_trials\n",
    "\n",
    "\n",
    "E_axis_a.cla()\n",
    "#E_axis_a.set_title('Optimal no of clusters')\n",
    "K_s = []\n",
    "K_s_CV = []\n",
    "models_list = range(1, no_of_animals + 1)\n",
    "for pos, animal in enumerate(models_list):\n",
    "    K_s.append(list(optimal_clusters_of_group[dataset_name(animal)][:,0]))\n",
    "    K_s_CV.append(list(optimal_clusters_of_group[dataset_name(animal)][:,1]))\n",
    "\n",
    "#test the correlation, scattering the data (eyeball it first):\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(x=list(chain(*K_s)), y=list(chain(*K_s_CV)))\n",
    "fig.savefig('scatter_K_CV.png')\n",
    "\n",
    "X = np.array(list(chain(*K_s)), dtype=int)\n",
    "Y = np.array(list(chain(*K_s_CV)), dtype=int) + 1\n",
    "sb.regplot(X, Y, ax=E_axis_a, marker='.', color='C0')\n",
    "tau, p_value = scipy.stats.pearsonr(X, Y)\n",
    "nb.report_value('K* to Assemblies correlation (Pearson)', (tau, p_value))\n",
    "#tau, p_value = scipy.stats.kendalltau(list(chain(*K_s)), list(chain(*K_s_CV)))\n",
    "#tau, p_value = scipy.stats.spearmanr(list(chain(*K_s)), list(chain(*K_s_CV)))\n",
    "xlim = (1 - 0.2, np.array(X).max() + 0.2)\n",
    "ylim = (1 - 0.2, np.array(Y).max() + 0.2)\n",
    "E_axis_a.set_xlim(xlim[0], xlim[1])\n",
    "E_axis_a.set_ylim(ylim[0], ylim[1])\n",
    "E_axis_a.set_xticks(list(range(math.ceil(xlim[0]), int(xlim[1]))))\n",
    "E_axis_a.set_yticks(list(range(math.ceil(ylim[0]), int(ylim[1]))))\n",
    "E_axis_a.set_xlabel('K*')\n",
    "E_axis_a.set_ylabel('Optimal assemblie no')\n",
    "nb.axis_normal_plot(E_axis_a)\n",
    "nb.adjust_spines(E_axis_a, ['left', 'bottom'])\n",
    "\n",
    "nb.mark_figure_letter(E_axis_a, 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure4.savefig('Figure_4_final.pdf')\n",
    "figure4.savefig('Figure_4_final.png')\n",
    "print('Tutto pronto!')\n",
    "\n",
    "\n",
    "#%%"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
