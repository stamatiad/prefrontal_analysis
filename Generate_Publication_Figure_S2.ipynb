{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Generate Figure 1\n",
    "Single neuron and network responses following stimulation. A. Top: Schematic representation of the network model. Excitatory (E) connectivity profile was based on experimental data. The excitatory population was reciprocally connected with the Inhibitory (I) in a feedback way. Bottom: Random network connectivity changes only excitatory connectivity. B. Top: Cartoon morphology of the pyramidal model. Bottom: Same for fast-spiking interneuron. C. Top: three exemplar responses of pyramidals in a single trial. Bottom: Same for interneurons. D. Top: Network response activity raster plot of pyramidal (blue) and interneurons (red) to a 1 sec stimulus. Bottom: Same trialâ€™s instantaneous firing frequencies of each pyramidal (> 20Hz), showing its highly dynamic response during delay period. E. Histograms of inter spike interval length (top) and Coefficient of Variation (bottom) of all the structured trials for the stimulus period (blue) and delay period (red). F. Top: Non-linear NMDA responses are generated in the basal dendrites of the pyramidal neurons (top) as in (Nevian et al. 2007b) (bottom). Somatic (blue) and dendritic (red) depolarization from resting potential in response to increasing stimulus intensity. G. Overall network response energy (mean firing rate; top) and multidimensional velocity (bottom) aligned on stimulus period onset. H. Top: Cross correlation of network states between the stimulus period and the delay period over time (aligned on stimulus onset, 1 s stimulus). Bottom: Experimentally reported correlation from (Murray et al. 2017). I.  Network responses for 10 trials, under one learning condition, reduced to their first three principal components. Colormap denotes time."
   ]
  },
  {
   "cell_type": "code",
   "collapsed": false,
   "language": "python",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Need to setup tools on our machine first:\n",
    "    !sudo apt-get install git-lfs\n",
    "    \n",
    "    # Due to github limitation in git lfs, I clone from an identical\n",
    "    # repo over bitbucket. To make sure the code in Github is identical\n",
    "    # you can clone the Github repo and run:\n",
    "    # >git diff review remotes/bitbucket/review\n",
    "    #!git clone https://github.com/stamatiad/prefrontal_analysis.git\n",
    "    !git clone https://bitbucket.org/stevest/prefrontal_analysis.git\n",
    "\n",
    "    import os\n",
    "    os.chdir('prefrontal_analysis')\n",
    "    !git checkout review\n",
    "\n",
    "    !git lfs install\n",
    "    !git lfs fetch\n",
    "    !git lfs checkout\n",
    "\n",
    "    !pip install -r requirements.txt\n",
    "\n",
    "    # numpy has issue: use version numpy==1.16.4\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import notebook_module as nb\n",
    "import analysis_tools as analysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pynwb import NWBHDF5IO\n",
    "from itertools import chain\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy import stats\n",
    "from pynwb import NWBFile\n",
    "from pynwb import NWBHDF5IO\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create figure 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simulations_dir = Path.cwd().joinpath('simulations')\n",
    "glia_dir = Path(r'G:\\Glia')\n",
    "plt.rcParams.update({'font.family': 'Helvetica'})\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 15)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "axis_label_font_size = 12\n",
    "tick_label_font_size = 12\n",
    "labelpad_x = 10\n",
    "labelpad_y = 10\n",
    "\n",
    "plt.ion()\n",
    "axis_label_font_size = 10\n",
    "no_of_conditions = 10\n",
    "no_of_animals = 4\n",
    "#===============================================================================\n",
    "#===============================================================================\n",
    "subplot_width = 2\n",
    "subplot_height = 1\n",
    "figure_ratio = subplot_height / subplot_width\n",
    "figure1 = plt.figure(figsize=plt.figaspect(figure_ratio))\n",
    "figure1.patch.set_facecolor('white')\n",
    "#TODO: I tend to believe that the w/hspace is RELATIVE to the size of this grid.\n",
    "# This asks for a absolute number, in order to have a visually pleasing grid.\n",
    "\n",
    "# c is the size of subplot space/margin, for both h/w (in figure scale).\n",
    "# If you are really OCD, you can use a second one, scaled by fig aspect ratio.\n",
    "cw = 0.05\n",
    "ch = cw / figure_ratio\n",
    "a_gs = nb.split_gridspec(2, 4, ch, cw, left=0.05, right=0.95, top=0.99, bottom=0.08)\n",
    "b_gs = nb.split_gridspec(3, 1, ch, cw, gs=a_gs[:, 1])\n",
    "c_gs = nb.split_gridspec(3, 1, ch, cw, gs=a_gs[:, 2])\n",
    "d_gs = nb.split_gridspec(3, 1, ch, cw, gs=a_gs[:, 3])\n",
    "\n",
    "A_axis_a = plt.subplot(a_gs[0, 0])\n",
    "A_axis_b = plt.subplot(a_gs[1, 0])\n",
    "nb.mark_figure_letter(A_axis_a, 'a')\n",
    "\n",
    "B_axis_a = plt.subplot(b_gs[0, :])\n",
    "B_axis_b = plt.subplot(b_gs[1, :])\n",
    "B_axis_c = plt.subplot(b_gs[2, :])\n",
    "nb.mark_figure_letter(B_axis_a, 'b')\n",
    "\n",
    "C_axis_a = plt.subplot(c_gs[0, :])\n",
    "C_axis_b = plt.subplot(c_gs[1, :])\n",
    "C_axis_c = plt.subplot(c_gs[2, :])\n",
    "nb.mark_figure_letter(C_axis_a, 'c')\n",
    "\n",
    "D_axis_a = plt.subplot(d_gs[0, :])\n",
    "D_axis_b = plt.subplot(d_gs[1, :])\n",
    "D_axis_c = plt.subplot(d_gs[2, :])\n",
    "nb.mark_figure_letter(D_axis_a, 'd')\n",
    "\n",
    "# Figure 1A\n",
    "# Lazy load the data as a NWB file.\n",
    "#TODO: Load the dense (single synapse steps) validation files.\n",
    "def create_nwb_validation_dense_file(inputdir=None, outputdir=None, **kwargs):\n",
    "    # Create a NWB file from the results of the validation routines.\n",
    "\n",
    "    print('Creating NWBfile.')\n",
    "    nwbfile = NWBFile(\n",
    "        session_description='NEURON validation results.',\n",
    "        identifier='excitatory_validation',\n",
    "        session_start_time=datetime.now(),\n",
    "        file_create_date=datetime.now()\n",
    "    )\n",
    "\n",
    "    # Partially automate the loading with the aid of a reading function;\n",
    "    # use a generic reading function that you make specific with partial and\n",
    "    # then just load all the trials:\n",
    "    synapse_activation = list(range(1, 25, 1))\n",
    "    basic_kwargs = {'ncells': 1, 'ntrials': len(synapse_activation), \\\n",
    "                    'stim_start_offset': 100, 'stim_stop_offset': 140,\n",
    "                    'trial_len': 700, 'samples_per_ms': 10}\n",
    "\n",
    "\n",
    "    # 'Freeze' some portion of the function, for a simplified one:\n",
    "    read_somatic_potential = partial(\n",
    "        analysis.read_validation_potential,\n",
    "        inputdir=inputdir,\n",
    "        synapse_activation=synapse_activation,\n",
    "        location='vsoma'\n",
    "    )\n",
    "\n",
    "    # Load first batch:\n",
    "    analysis.import_recordings_to_nwb(\n",
    "        nwbfile=nwbfile,\n",
    "        read_function=partial(\n",
    "            read_somatic_potential,\n",
    "            condition='normal',\n",
    "            currents='NMDA+AMPA',\n",
    "            nmda_bias=6.0,\n",
    "            ampa_bias=1.0,\n",
    "        ),\n",
    "        timeseries_name='normal_NMDA+AMPA',\n",
    "        timeseries_description='Validation',\n",
    "        **basic_kwargs\n",
    "    )\n",
    "\n",
    "    # Rinse and repeat:\n",
    "    analysis.import_recordings_to_nwb(\n",
    "        nwbfile=nwbfile,\n",
    "        read_function=partial(\n",
    "            read_somatic_potential,\n",
    "            condition='normal',\n",
    "            currents='AMPA',\n",
    "            nmda_bias=0.0,\n",
    "            ampa_bias=50.0,\n",
    "        ),\n",
    "        timeseries_name='normal_AMPA_only',\n",
    "        timeseries_description='Validation',\n",
    "        **basic_kwargs\n",
    "    )\n",
    "\n",
    "    # Rinse and repeat:\n",
    "    analysis.import_recordings_to_nwb(\n",
    "        nwbfile=nwbfile,\n",
    "        read_function=partial(\n",
    "            read_somatic_potential,\n",
    "            condition='noMg',\n",
    "            currents='NMDA+AMPA',\n",
    "            nmda_bias=6.0,\n",
    "            ampa_bias=1.0,\n",
    "        ),\n",
    "        timeseries_name='noMg_NMDA+AMPA',\n",
    "        timeseries_description='Validation',\n",
    "        **basic_kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "    # Use partial to remove some of the kwargs that are the same:\n",
    "    read_dendritic_potential = partial(\n",
    "        analysis.read_validation_potential,\n",
    "        inputdir=inputdir,\n",
    "        synapse_activation=synapse_activation,\n",
    "        location='vdend'\n",
    "    )\n",
    "\n",
    "    # Load dendritic potential:\n",
    "    analysis.import_recordings_to_nwb(\n",
    "        nwbfile=nwbfile,\n",
    "        read_function=partial(\n",
    "            read_dendritic_potential,\n",
    "            condition='normal',\n",
    "            currents='NMDA+AMPA',\n",
    "            nmda_bias=6.0,\n",
    "            ampa_bias=1.0,\n",
    "        ),\n",
    "        timeseries_name='vdend_normal_NMDA+AMPA',\n",
    "        timeseries_description='Validation',\n",
    "        **basic_kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "    # write to file:\n",
    "    output_file = outputdir.joinpath(\n",
    "        'excitatory_dense_validation.nwb'\n",
    "    )\n",
    "    print(f'Writing to NWBfile: {output_file}')\n",
    "    with NWBHDF5IO(str(output_file), 'w') as io:\n",
    "        io.write(nwbfile)\n",
    "\n",
    "\n",
    "# Create the new validation file:\n",
    "# for structured condition:\n",
    "if False:\n",
    "    inputdir = Path(r'W:\\taxidi\\analysis\\Glia\\publication_validation\\excitatory_validation_dense')\n",
    "    outputdir = Path(r'W:\\taxidi\\analysis\\Python\\simulations')\n",
    "    try:\n",
    "        create_nwb_validation_dense_file(\n",
    "            inputdir=inputdir,\n",
    "            outputdir=outputdir\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "    print('Done converting validation params and exiting.')\n",
    "\n",
    "def plot_cross_correlation(NWBfile, plot_axis):\n",
    "    # Add cross correlation:\n",
    "    trial_len, pn_no, ntrials, trial_q_no = analysis.get_acquisition_parameters(\n",
    "        input_NWBfile=NWBfile,\n",
    "        requested_parameters=['trial_len', 'pn_no', 'ntrials', 'trial_q_no']\n",
    "    )\n",
    "    custom_range = (0, int(trial_len / 50))\n",
    "    # Load binned acquisition (all trials together)\n",
    "    binned_network_activity = NWBfile.acquisition['binned_activity'] \\\n",
    "                                  .data[:pn_no, :] \\\n",
    "        .reshape(pn_no, ntrials, trial_q_no)\n",
    "\n",
    "    # Perform correlation in each time bin state:\n",
    "    #TODO: giati ta trials einai 9 (pou shmainei oti anixneftikan only PA ones),\n",
    "    # alla to trial 0 den exei PA?\n",
    "    single_trial_activity = binned_network_activity[\n",
    "                            :pn_no, 7, custom_range[0]:custom_range[1]\n",
    "                            ]\n",
    "    duration = single_trial_activity.shape[1]\n",
    "    timelag_corr = np.zeros((duration, duration))\n",
    "    for ii in range(duration):\n",
    "        for jj in range(duration):\n",
    "            S = np.corrcoef(\n",
    "                single_trial_activity[:, ii],\n",
    "                single_trial_activity[:, jj]\n",
    "            )\n",
    "            timelag_corr[ii, jj] = S[0, 1]\n",
    "\n",
    "    #figure1, plot_axes = plt.subplots()\n",
    "    im = plot_axis.imshow(timelag_corr, vmin=0.7)\n",
    "    plot_axis.xaxis.tick_top()\n",
    "    for axis in ['top', 'bottom', 'left', 'right']:\n",
    "        plot_axis.spines[axis].set_linewidth(2)\n",
    "    plot_axis.xaxis.set_tick_params(width=2)\n",
    "    plot_axis.yaxis.set_tick_params(width=2)\n",
    "    time_axis_limits = (0, duration)\n",
    "    #TODO: change the 20 with a proper variable (do I have one?)\n",
    "    time_axis_ticks = np.linspace(0, duration, (duration / 20) + 1)\n",
    "    time_axis_ticklabels = analysis.q2sec(q_time=time_axis_ticks).astype(int)  #np.linspace(0, time_axis_limits[1], duration)\n",
    "    plot_axis.set_xticks(time_axis_ticks)\n",
    "    plot_axis.set_xticklabels(time_axis_ticklabels, fontsize=tick_label_font_size)\n",
    "    plot_axis.set_yticks(time_axis_ticks)\n",
    "    plot_axis.set_yticklabels(time_axis_ticklabels, fontsize=tick_label_font_size)\n",
    "    plot_axis.set_ylabel(\n",
    "        'Time (s)', fontsize=axis_label_font_size,\n",
    "        labelpad=labelpad_y\n",
    "    )\n",
    "    #plot_axis.set_xlabel('')\n",
    "    # create an axes on the right side of ax. The width of cax will be 5%\n",
    "    # of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "    divider = make_axes_locatable(plot_axis)\n",
    "    cax = divider.append_axes('bottom', size='5%', pad=0.05)\n",
    "    figure1.colorbar(im, orientation='horizontal', fraction=0.05,\n",
    "                     cax=cax)\n",
    "    cax.set_xlabel(\n",
    "        'Correlation', fontsize=axis_label_font_size,\n",
    "        labelpad=labelpad_x\n",
    "    )\n",
    "# Call the analysis on it:\n",
    "input_NWBfile = simulations_dir.joinpath('excitatory_dense_validation.nwb')\n",
    "nwbfile = NWBHDF5IO(str(input_NWBfile), 'r').read()\n",
    "per_trial_activity = {}\n",
    "per_trial_activity['soma_NMDA+AMPA'] = analysis.separate_trials(\n",
    "    input_NWBfile=nwbfile, acquisition_name='normal_NMDA+AMPA'\n",
    ")\n",
    "per_trial_activity['normal_AMPA_only'] = analysis.separate_trials(\n",
    "    input_NWBfile=nwbfile, acquisition_name='normal_AMPA_only'\n",
    ")\n",
    "per_trial_activity['noMg_NMDA+AMPA'] = analysis.separate_trials(\n",
    "    input_NWBfile=nwbfile, acquisition_name='noMg_NMDA+AMPA'\n",
    ")\n",
    "\n",
    "normal_amplitude = [\n",
    "    trace[0][500:5000].max() - trace[0][400]\n",
    "    for trace in per_trial_activity['soma_NMDA+AMPA']\n",
    "]\n",
    "ampa_amplitude = [\n",
    "    trace[0][500:5000].max() - trace[0][400]\n",
    "    for trace in per_trial_activity['normal_AMPA_only']\n",
    "]\n",
    "mg_amplitude = [\n",
    "    trace[0][500:5000].max() - trace[0][400]\n",
    "    for trace in per_trial_activity['noMg_NMDA+AMPA']\n",
    "]\n",
    "A_axis_a.plot(normal_amplitude[:25], color='C0')\n",
    "A_axis_a.plot(ampa_amplitude[:25], color='C1')\n",
    "A_axis_a.set_xlabel('Stimulus intensity', fontsize=axis_label_font_size)\n",
    "A_axis_a.set_ylabel('Amplitude (mV)', fontsize=axis_label_font_size)\n",
    "A_axis_a.set_xticks(range(0, len(normal_amplitude[:25]), 5))\n",
    "A_axis_a.set_xticklabels(range(1, len(normal_amplitude[:25]) + 1, 5))\n",
    "nb.axis_normal_plot(axis=A_axis_a)\n",
    "nb.adjust_spines(A_axis_a, ['left', 'bottom'])\n",
    "\n",
    "A_axis_b.plot(normal_amplitude[:25], color='C0')\n",
    "A_axis_b.plot(mg_amplitude[:25], color='C1')\n",
    "A_axis_b.set_xlabel('Stimulus intensity', fontsize=axis_label_font_size)\n",
    "A_axis_b.set_ylabel('Amplitude (mV)', fontsize=axis_label_font_size)\n",
    "A_axis_b.set_xticks(range(0, len(normal_amplitude[:25]), 5))\n",
    "A_axis_b.set_xticklabels(range(1, len(normal_amplitude[:25]) + 1, 5))\n",
    "nb.axis_normal_plot(axis=A_axis_b)\n",
    "nb.adjust_spines(A_axis_b, ['left', 'bottom'])\n",
    "\n",
    "\n",
    "# Figure S2b\n",
    "# Plot firing frequencies of non-NMDA, random configurations.\n",
    "stim_ISI_all = []\n",
    "stim_ISI_CV_all = []\n",
    "delay_ISI_all = []\n",
    "delay_ISI_CV_all = []\n",
    "no_of_conditions = 5\n",
    "for animal_model in range(1, no_of_animals + 1):\n",
    "    for learning_condition in range(1, no_of_conditions + 1):\n",
    "        NWBfile = analysis.load_nwb_file(\n",
    "            animal_model=animal_model,\n",
    "            learning_condition=learning_condition,\n",
    "            experiment_config='structured_nonmda',\n",
    "            type='bn',\n",
    "            data_path=simulations_dir\n",
    "        )\n",
    "        # Calculate ISI and its CV:\n",
    "        stim_ISIs, stim_ISIs_CV = analysis.calculate_stimulus_isi(NWBfile)\n",
    "        delay_ISIs, delay_ISIs_CV = analysis.calculate_delay_isi(NWBfile)\n",
    "\n",
    "        stim_ISI_all.append(stim_ISIs)\n",
    "        stim_ISI_CV_all.append(stim_ISIs_CV)\n",
    "        delay_ISI_all.append(delay_ISIs)\n",
    "        delay_ISI_CV_all.append(delay_ISIs_CV)\n",
    "\n",
    "stim_ISI = list(chain(*stim_ISI_all))\n",
    "delay_ISI = list(chain(*delay_ISI_all))\n",
    "stim_ISI_CV = list(chain(*stim_ISI_CV_all))\n",
    "delay_ISI_CV = list(chain(*delay_ISI_CV_all))\n",
    "step_isi = 20\n",
    "step_cv = 0.2\n",
    "bins_isi = np.arange(0, 200, step_isi)\n",
    "bins_cv = np.arange(0, 2, step_cv)\n",
    "stim_isi_hist, *_ = np.histogram(stim_ISI, bins=bins_isi)\n",
    "delay_isi_hist, *_ = np.histogram(delay_ISI, bins=bins_isi)\n",
    "stim_isi_cv_hist, *_ = np.histogram(stim_ISI_CV, bins=bins_cv)\n",
    "delay_isi_cv_hist, *_ = np.histogram(delay_ISI_CV, bins=bins_cv)\n",
    "\n",
    "# Do Kruskar Wallis test on distributions:\n",
    "kruskal_result_cv = stats.kruskal(stim_ISI_CV, delay_ISI_CV, nan_policy='omit')\n",
    "kruskal_result_isi = stats.kruskal(stim_ISI, delay_ISI, nan_policy='omit')\n",
    "\n",
    "average_stim_isi = np.mean(stim_ISI)\n",
    "average_delay_isi = np.mean(delay_ISI)\n",
    "average_stim_cv = np.nanmean(stim_ISI_CV)\n",
    "average_delay_cv = np.nanmean(delay_ISI_CV)\n",
    "\n",
    "std_stim_isi = np.std(stim_ISI)\n",
    "std_delay_isi = np.std(delay_ISI)\n",
    "std_stim_cv = np.nanstd(stim_ISI_CV)\n",
    "std_delay_cv = np.nanstd(delay_ISI_CV)\n",
    "\n",
    "nb.report_value(f'Fig S2B: CV stim mean', average_stim_cv)\n",
    "nb.report_value(f'Fig S2B: CV stim std', std_stim_cv)\n",
    "nb.report_value(f'Fig S2B: CV delay mean', average_delay_cv)\n",
    "nb.report_value(f'Fig S2B: CV delay std', std_delay_cv)\n",
    "\n",
    "nb.report_value(f'Fig S2B: ISI stim mean', average_stim_isi)\n",
    "nb.report_value(f'Fig S2B: ISI stim std', std_stim_isi)\n",
    "nb.report_value(f'Fig S2B: ISI delay mean', average_delay_isi)\n",
    "nb.report_value(f'Fig S2B: ISI delay std', std_delay_isi)\n",
    "\n",
    "nb.report_value(f'Fig S2B: CV Kruskal p', kruskal_result_cv.pvalue)\n",
    "nb.report_value(f'Fig S2B: ISI Kruskal p', kruskal_result_isi.pvalue)\n",
    "\n",
    "B_axis_a.plot(stim_isi_hist / stim_isi_hist.sum(), color='C0')\n",
    "B_axis_a.axvline(np.mean(stim_ISI) / step_isi, color='C0', linestyle='--')\n",
    "B_axis_a.plot(delay_isi_hist / delay_isi_hist.sum(), color='C1')\n",
    "B_axis_a.axvline(np.mean(delay_ISI) / step_isi, color='C1', linestyle='--')\n",
    "B_axis_a.set_xticks(range(0, bins_isi.size, 2))\n",
    "B_axis_a.set_xticklabels(np.round(bins_isi * 2, 1), fontsize=tick_label_font_size)\n",
    "B_axis_a.set_xlim([0.0, bins_isi.size])\n",
    "B_axis_a.set_xlabel(\n",
    "    'ISI length (ms)', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "B_axis_a.set_ylabel(\n",
    "    'Relative Frequency', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "nb.axis_normal_plot(axis=B_axis_a)\n",
    "nb.adjust_spines(B_axis_a, ['left', 'bottom'])\n",
    "#TODO: Why I have nans inside CV?\n",
    "B_axis_b.plot(stim_isi_cv_hist / stim_isi_cv_hist.sum(), color='C0')\n",
    "B_axis_b.axvline(np.nanmean(stim_ISI_CV) / step_cv, color='C0', linestyle='--')\n",
    "B_axis_b.plot(delay_isi_cv_hist / delay_isi_cv_hist.sum(), color='C1')\n",
    "B_axis_b.axvline(np.nanmean(delay_ISI_CV) / step_cv, color='C1', linestyle='--')\n",
    "B_axis_b.set_xticks(range(0, bins_cv.size, 2))\n",
    "B_axis_b.set_xticklabels(np.round(bins_cv * 2, 1), fontsize=tick_label_font_size)\n",
    "B_axis_b.set_xlim([0.0, bins_cv.size])\n",
    "B_axis_b.set_xlabel(\n",
    "    'Coefficient of Variation', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "B_axis_b.set_ylabel(\n",
    "    'Relative Frequency', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "nb.axis_normal_plot(axis=B_axis_b)\n",
    "nb.adjust_spines(B_axis_b, ['left', 'bottom'])\n",
    "nb.mark_figure_letter(B_axis_a, 'b')\n",
    "plot_cross_correlation(NWBfile, B_axis_c)\n",
    "\n",
    "\n",
    "\n",
    "# Figure S2c\n",
    "# Plot firing frequencies of non-Mg, random configurations.\n",
    "stim_ISI_all = []\n",
    "stim_ISI_CV_all = []\n",
    "delay_ISI_all = []\n",
    "delay_ISI_CV_all = []\n",
    "no_of_animals = 1\n",
    "no_of_conditions = 5\n",
    "for animal_model in range(1, no_of_animals + 1):\n",
    "    for learning_condition in range(1, no_of_conditions + 1):\n",
    "        NWBfile = analysis.load_nwb_file(\n",
    "            animal_model=animal_model,\n",
    "            learning_condition=learning_condition,\n",
    "            experiment_config='structured_nomg',\n",
    "            type='bn',\n",
    "            data_path=simulations_dir\n",
    "        )\n",
    "        # Calculate ISI and its CV:\n",
    "        stim_ISIs, stim_ISIs_CV = analysis.calculate_stimulus_isi(NWBfile)\n",
    "        delay_ISIs, delay_ISIs_CV = analysis.calculate_delay_isi(NWBfile)\n",
    "\n",
    "        stim_ISI_all.append(stim_ISIs)\n",
    "        stim_ISI_CV_all.append(stim_ISIs_CV)\n",
    "        delay_ISI_all.append(delay_ISIs)\n",
    "        delay_ISI_CV_all.append(delay_ISIs_CV)\n",
    "\n",
    "stim_ISI = list(chain(*stim_ISI_all))\n",
    "delay_ISI = list(chain(*delay_ISI_all))\n",
    "stim_ISI_CV = list(chain(*stim_ISI_CV_all))\n",
    "delay_ISI_CV = list(chain(*delay_ISI_CV_all))\n",
    "step_isi = 20\n",
    "step_cv = 0.2\n",
    "bins_isi = np.arange(0, 200, step_isi)\n",
    "bins_cv = np.arange(0, 2, step_cv)\n",
    "stim_isi_hist, *_ = np.histogram(stim_ISI, bins=bins_isi)\n",
    "delay_isi_hist, *_ = np.histogram(delay_ISI, bins=bins_isi)\n",
    "stim_isi_cv_hist, *_ = np.histogram(stim_ISI_CV, bins=bins_cv)\n",
    "delay_isi_cv_hist, *_ = np.histogram(delay_ISI_CV, bins=bins_cv)\n",
    "\n",
    "# Do Kruskar Wallis test on distributions:\n",
    "kruskal_result_cv = stats.kruskal(stim_ISI_CV, delay_ISI_CV, nan_policy='omit')\n",
    "kruskal_result_isi = stats.kruskal(stim_ISI, delay_ISI, nan_policy='omit')\n",
    "\n",
    "average_stim_isi = np.mean(stim_ISI)\n",
    "average_delay_isi = np.mean(delay_ISI)\n",
    "average_stim_cv = np.nanmean(stim_ISI_CV)\n",
    "average_delay_cv = np.nanmean(delay_ISI_CV)\n",
    "\n",
    "std_stim_isi = np.std(stim_ISI)\n",
    "std_delay_isi = np.std(delay_ISI)\n",
    "std_stim_cv = np.nanstd(stim_ISI_CV)\n",
    "std_delay_cv = np.nanstd(delay_ISI_CV)\n",
    "\n",
    "nb.report_value(f'Fig S2C: CV stim mean', average_stim_cv)\n",
    "nb.report_value(f'Fig S2C: CV stim std', std_stim_cv)\n",
    "nb.report_value(f'Fig S2C: CV delay mean', average_delay_cv)\n",
    "nb.report_value(f'Fig S2C: CV delay std', std_delay_cv)\n",
    "\n",
    "nb.report_value(f'Fig S2C: ISI stim mean', average_stim_isi)\n",
    "nb.report_value(f'Fig S2C: ISI stim std', std_stim_isi)\n",
    "nb.report_value(f'Fig S2C: ISI delay mean', average_delay_isi)\n",
    "nb.report_value(f'Fig S2C: ISI delay std', std_delay_isi)\n",
    "\n",
    "nb.report_value(f'Fig S2C: CV Kruskal p', kruskal_result_cv.pvalue)\n",
    "nb.report_value(f'Fig S2C: ISI Kruskal p', kruskal_result_isi.pvalue)\n",
    "\n",
    "C_axis_a.plot(stim_isi_hist / stim_isi_hist.sum(), color='C0')\n",
    "C_axis_a.axvline(np.mean(stim_ISI) / step_isi, color='C0', linestyle='--')\n",
    "C_axis_a.plot(delay_isi_hist / delay_isi_hist.sum(), color='C1')\n",
    "C_axis_a.axvline(np.mean(delay_ISI) / step_isi, color='C1', linestyle='--')\n",
    "C_axis_a.set_xticks(range(0, bins_isi.size, 2))\n",
    "C_axis_a.set_xticklabels(np.round(bins_isi * 2, 1), fontsize=tick_label_font_size)\n",
    "C_axis_a.set_xlim([0.0, bins_isi.size])\n",
    "C_axis_a.set_xlabel(\n",
    "    'ISI length (ms)', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "C_axis_a.set_ylabel(\n",
    "    'Relative Frequency', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "nb.axis_normal_plot(axis=C_axis_a)\n",
    "nb.adjust_spines(C_axis_a, ['left', 'bottom'])\n",
    "#TODO: Why I have nans inside CV?\n",
    "C_axis_b.plot(stim_isi_cv_hist / stim_isi_cv_hist.sum(), color='C0')\n",
    "C_axis_b.axvline(np.nanmean(stim_ISI_CV) / step_cv, color='C0', linestyle='--')\n",
    "C_axis_b.plot(delay_isi_cv_hist / delay_isi_cv_hist.sum(), color='C1')\n",
    "C_axis_b.axvline(np.nanmean(delay_ISI_CV) / step_cv, color='C1', linestyle='--')\n",
    "C_axis_b.set_xticks(range(0, bins_cv.size, 2))\n",
    "C_axis_b.set_xticklabels(np.round(bins_cv * 2, 1), fontsize=tick_label_font_size)\n",
    "C_axis_b.set_xlim([0.0, bins_cv.size])\n",
    "C_axis_b.set_xlabel(\n",
    "    'Coefficient of Variation', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "C_axis_b.set_ylabel(\n",
    "    'Relative Frequency', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "nb.axis_normal_plot(axis=C_axis_b)\n",
    "nb.adjust_spines(C_axis_b, ['left', 'bottom'])\n",
    "nb.mark_figure_letter(C_axis_a, 'c')\n",
    "plot_cross_correlation(NWBfile, C_axis_c)\n",
    "\n",
    "# Figure S2d\n",
    "# Plot firing frequencies of non-Mg, random configurations.\n",
    "stim_ISI_all = []\n",
    "stim_ISI_CV_all = []\n",
    "delay_ISI_all = []\n",
    "delay_ISI_CV_all = []\n",
    "no_of_animals = 4\n",
    "no_of_conditions = 10\n",
    "for animal_model in range(1, no_of_animals + 1):\n",
    "    for learning_condition in range(1, no_of_conditions + 1):\n",
    "        NWBfile = analysis.load_nwb_file(\n",
    "            animal_model=animal_model,\n",
    "            learning_condition=learning_condition,\n",
    "            experiment_config='random',\n",
    "            type='bn',\n",
    "            data_path=simulations_dir\n",
    "        )\n",
    "        # Calculate ISI and its CV:\n",
    "        stim_ISIs, stim_ISIs_CV = analysis.calculate_stimulus_isi(NWBfile)\n",
    "        delay_ISIs, delay_ISIs_CV = analysis.calculate_delay_isi(NWBfile)\n",
    "\n",
    "        stim_ISI_all.append(stim_ISIs)\n",
    "        stim_ISI_CV_all.append(stim_ISIs_CV)\n",
    "        delay_ISI_all.append(delay_ISIs)\n",
    "        delay_ISI_CV_all.append(delay_ISIs_CV)\n",
    "\n",
    "stim_ISI = list(chain(*stim_ISI_all))\n",
    "delay_ISI = list(chain(*delay_ISI_all))\n",
    "stim_ISI_CV = list(chain(*stim_ISI_CV_all))\n",
    "delay_ISI_CV = list(chain(*delay_ISI_CV_all))\n",
    "step_isi = 20\n",
    "step_cv = 0.2\n",
    "bins_isi = np.arange(0, 200, step_isi)\n",
    "bins_cv = np.arange(0, 2, step_cv)\n",
    "stim_isi_hist, *_ = np.histogram(stim_ISI, bins=bins_isi)\n",
    "delay_isi_hist, *_ = np.histogram(delay_ISI, bins=bins_isi)\n",
    "stim_isi_cv_hist, *_ = np.histogram(stim_ISI_CV, bins=bins_cv)\n",
    "delay_isi_cv_hist, *_ = np.histogram(delay_ISI_CV, bins=bins_cv)\n",
    "\n",
    "# Do Kruskar Wallis test on distributions:\n",
    "kruskal_result_cv = stats.kruskal(stim_ISI_CV, delay_ISI_CV, nan_policy='omit')\n",
    "kruskal_result_isi = stats.kruskal(stim_ISI, delay_ISI, nan_policy='omit')\n",
    "\n",
    "average_stim_isi = np.mean(stim_ISI)\n",
    "average_delay_isi = np.mean(delay_ISI)\n",
    "average_stim_cv = np.nanmean(stim_ISI_CV)\n",
    "average_delay_cv = np.nanmean(delay_ISI_CV)\n",
    "\n",
    "std_stim_isi = np.std(stim_ISI)\n",
    "std_delay_isi = np.std(delay_ISI)\n",
    "std_stim_cv = np.nanstd(stim_ISI_CV)\n",
    "std_delay_cv = np.nanstd(delay_ISI_CV)\n",
    "\n",
    "nb.report_value(f'Fig S2D: CV stim mean', average_stim_cv)\n",
    "nb.report_value(f'Fig S2D: CV stim std', std_stim_cv)\n",
    "nb.report_value(f'Fig S2D: CV delay mean', average_delay_cv)\n",
    "nb.report_value(f'Fig S2D: CV delay std', std_delay_cv)\n",
    "\n",
    "nb.report_value(f'Fig S2D: ISI stim mean', average_stim_isi)\n",
    "nb.report_value(f'Fig S2D: ISI stim std', std_stim_isi)\n",
    "nb.report_value(f'Fig S2D: ISI delay mean', average_delay_isi)\n",
    "nb.report_value(f'Fig S2D: ISI delay std', std_delay_isi)\n",
    "\n",
    "nb.report_value(f'Fig S2D: CV Kruskal p', kruskal_result_cv.pvalue)\n",
    "nb.report_value(f'Fig S2D: ISI Kruskal p', kruskal_result_isi.pvalue)\n",
    "\n",
    "D_axis_a.plot(stim_isi_hist / stim_isi_hist.sum(), color='C0')\n",
    "D_axis_a.axvline(np.mean(stim_ISI) / step_isi, color='C0', linestyle='--')\n",
    "D_axis_a.plot(delay_isi_hist / delay_isi_hist.sum(), color='C1')\n",
    "D_axis_a.axvline(np.mean(delay_ISI) / step_isi, color='C1', linestyle='--')\n",
    "D_axis_a.set_xticks(range(0, bins_isi.size, 2))\n",
    "D_axis_a.set_xticklabels(np.round(bins_isi * 2, 1), fontsize=tick_label_font_size)\n",
    "D_axis_a.set_xlim([0.0, bins_isi.size])\n",
    "D_axis_a.set_xlabel(\n",
    "    'ISI length (ms)', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "D_axis_a.set_ylabel(\n",
    "    'Relative Frequency', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "nb.axis_normal_plot(axis=D_axis_a)\n",
    "nb.adjust_spines(D_axis_a, ['left', 'bottom'])\n",
    "#TODO: Why I have nans inside CV?\n",
    "D_axis_b.plot(stim_isi_cv_hist / len(stim_ISI_CV), color='C0')\n",
    "D_axis_b.axvline(np.nanmean(stim_ISI_CV) / step_cv, color='C0', linestyle='--')\n",
    "D_axis_b.plot(delay_isi_cv_hist / len(delay_ISI_CV), color='C1')\n",
    "D_axis_b.axvline(np.nanmean(delay_ISI_CV) / step_cv, color='C1', linestyle='--')\n",
    "D_axis_b.set_xticks(range(0, bins_cv.size, 2))\n",
    "D_axis_b.set_xticklabels(np.round(bins_cv * 2, 1), fontsize=tick_label_font_size)\n",
    "D_axis_b.set_xlim([0.0, bins_cv.size])\n",
    "D_axis_b.set_xlabel(\n",
    "    'Coefficient of Variation', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "D_axis_b.set_ylabel(\n",
    "    'Relative Frequency', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "nb.axis_normal_plot(axis=D_axis_b)\n",
    "nb.adjust_spines(D_axis_b, ['left', 'bottom'])\n",
    "nb.mark_figure_letter(D_axis_a, 'd')\n",
    "plot_cross_correlation(NWBfile, D_axis_c)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure1.savefig('Figure_S2_new.png')\n",
    "figure1.savefig('Figure_S2_new.pdf')\n",
    "print('Tutto pronto!')\n",
    "\n",
    "\n",
    "#%%"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
