{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Generate Figure 1\n",
    "Single neuron and network responses following stimulation. A. Top: Schematic representation of the network model. Excitatory (E) connectivity profile was based on experimental data. The excitatory population was reciprocally connected with the Inhibitory (I) in a feedback way. Bottom: Random network connectivity changes only excitatory connectivity. B. Top: Cartoon morphology of the pyramidal model. Bottom: Same for fast-spiking interneuron. C. Top: three exemplar responses of pyramidals in a single trial. Bottom: Same for interneurons. D. Top: Network response activity raster plot of pyramidal (blue) and interneurons (red) to a 1 sec stimulus. Bottom: Same trialâ€™s instantaneous firing frequencies of each pyramidal (> 20Hz), showing its highly dynamic response during delay period. E. Histograms of inter spike interval length (top) and Coefficient of Variation (bottom) of all the structured trials for the stimulus period (blue) and delay period (red). F. Top: Non-linear NMDA responses are generated in the basal dendrites of the pyramidal neurons (top) as in (Nevian et al. 2007b) (bottom). Somatic (blue) and dendritic (red) depolarization from resting potential in response to increasing stimulus intensity. G. Overall network response energy (mean firing rate; top) and multidimensional velocity (bottom) aligned on stimulus period onset. H. Top: Cross correlation of network states between the stimulus period and the delay period over time (aligned on stimulus onset, 1 s stimulus). Bottom: Experimentally reported correlation from (Murray et al. 2017). I.  Network responses for 10 trials, under one learning condition, reduced to their first three principal components. Colormap denotes time."
   ]
  },
  {
   "cell_type": "code",
   "collapsed": false,
   "language": "python",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Need to setup tools on our machine first:\n",
    "    !sudo apt-get install git-lfs\n",
    "    \n",
    "    # Due to github limitation in git lfs, I clone from an identical\n",
    "    # repo over bitbucket. To make sure the code in Github is identical\n",
    "    # you can clone the Github repo and run:\n",
    "    # >git diff review remotes/bitbucket/review\n",
    "    #!git clone https://github.com/stamatiad/prefrontal_analysis.git\n",
    "    !git clone https://bitbucket.org/stevest/prefrontal_analysis.git\n",
    "\n",
    "    import os\n",
    "    os.chdir('prefrontal_analysis')\n",
    "    !git checkout review\n",
    "\n",
    "    !git lfs install\n",
    "    !git lfs fetch\n",
    "    !git lfs checkout\n",
    "\n",
    "    !pip install -r requirements.txt\n",
    "\n",
    "    # numpy has issue: use version numpy==1.16.4\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import notebook_module as nb\n",
    "import analysis_tools as analysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pynwb import NWBHDF5IO\n",
    "from itertools import chain\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy import stats\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create figure 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simulations_dir = Path.cwd().joinpath('simulations')\n",
    "#Changes between computers.\n",
    "glia_dir = Path.cwd().joinpath('simulations')\n",
    "plt.rcParams.update({'font.family': 'Helvetica'})\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 15)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "axis_label_font_size = 12\n",
    "tick_label_font_size = 12\n",
    "labelpad_x = 10\n",
    "labelpad_y = 10\n",
    "\n",
    "plt.ion()\n",
    "no_of_conditions = 10\n",
    "no_of_animals = 4\n",
    "#===============================================================================\n",
    "#===============================================================================\n",
    "# FIGURE 1 (PENDING)\n",
    "\n",
    "# Create the figure objects:\n",
    "subplot_width = 5\n",
    "subplot_height = 4\n",
    "figure_ratio = subplot_height / subplot_width\n",
    "figure1 = plt.figure(figsize=plt.figaspect(figure_ratio))\n",
    "figure1.patch.set_facecolor('white')\n",
    "\n",
    "# c is the size of subplot space/margin, for both h/w (in figure scale).\n",
    "# If you are really OCD, you can use a second one, scaled by fig aspect ratio.\n",
    "cw = 0.05\n",
    "ch = cw / figure_ratio\n",
    "main_gs = nb.split_gridspec(2, 1, ch, cw, left=0.05, right=0.95, top=0.99, bottom=0.08)\n",
    "upper_gs = nb.split_gridspec(1, 3, ch, cw, gs=main_gs[0, :])\n",
    "lower_gs = nb.split_gridspec(1, 4, ch, cw, gs=main_gs[1, :])\n",
    "#upper_gs = main_gs[0, :].subgridspec(1, 3, wspace=0.15, hspace=0.15)\n",
    "#lower_gs = main_gs[1, :].subgridspec(1, 2, wspace=0.15, hspace=0.15)\n",
    "AB_gs = nb.split_gridspec(2, 2, ch, cw, gs=upper_gs[0, 0])\n",
    "#AB_gs = upper_gs[0, 0].subgridspec(2, 2, wspace=0.15, hspace=new_p)\n",
    "A_axis_a = plt.subplot(AB_gs[0, 0])\n",
    "A_axis_b = plt.subplot(AB_gs[0, 1])\n",
    "B_axis_a = plt.subplot(AB_gs[1, :])\n",
    "nb.mark_figure_letter(A_axis_a, 'a')\n",
    "nb.mark_figure_letter(B_axis_a, 'b')\n",
    "\n",
    "CD_gs = nb.split_gridspec(6, 4, ch, cw, gs=upper_gs[0, 1:])\n",
    "#CD_gs = upper_gs[0, 1:].subgridspec(6, 4, wspace=0.15, hspace=new_p)\n",
    "C_gs = CD_gs[:, :3].subgridspec(6, 1, hspace=0.1)\n",
    "C_axis_a = plt.subplot(C_gs[0, 0])\n",
    "C_axis_b = plt.subplot(C_gs[1, 0])\n",
    "C_axis_c = plt.subplot(C_gs[2, 0])\n",
    "C_axis_d = plt.subplot(C_gs[3, 0])\n",
    "C_axis_e = plt.subplot(C_gs[4, 0])\n",
    "C_axis_f = plt.subplot(C_gs[5, 0])\n",
    "nb.mark_figure_letter(C_axis_a, 'c')\n",
    "D_axis_a = plt.subplot(CD_gs[:3, 3:])\n",
    "D_axis_b = plt.subplot(CD_gs[3:, 3:])\n",
    "nb.mark_figure_letter(D_axis_a, 'd')\n",
    "\n",
    "E_gs = nb.split_gridspec(2, 1, ch, cw, gs=lower_gs[0, :2])\n",
    "#E_gs = lower_gs[0, 0].subgridspec(2, 1, wspace=0.15, hspace=0.15*2)\n",
    "E_axis_a = plt.subplot(E_gs[0, :])\n",
    "E_axis_b = plt.subplot(E_gs[1, :])\n",
    "nb.mark_figure_letter(E_axis_a, 'e')\n",
    "FGH_gs = nb.split_gridspec(2, 3, ch, cw, gs=lower_gs[0, 2:])\n",
    "#FGHI_gs = lower_gs[0, 1].subgridspec(1, 3, wspace=0.15, hspace=0.15)\n",
    "#FGH_gs = nb.split_gridspec(2, 2, ch, cw, gs=FGHI_gs[0, 0])\n",
    "#FGH_gs = FGHI_gs[0, 0].subgridspec(5, 1, wspace=0.15, hspace=0.15*5)\n",
    "F_axis_a = plt.subplot(FGH_gs[:, :2])\n",
    "nb.mark_figure_letter(F_axis_a, 'f')\n",
    "G_axis_a = plt.subplot(FGH_gs[0, 2])\n",
    "nb.mark_figure_letter(G_axis_a, 'g')\n",
    "H_axis_a = plt.subplot(FGH_gs[1, 2])\n",
    "nb.mark_figure_letter(H_axis_a, 'h')\n",
    "\n",
    "plt.show()\n",
    "figure1.savefig('FINAL.png')\n",
    "print('Tutto pronto!')\n",
    "\n",
    "\n",
    "sketch_pyramidal = plt.imread('Pyramidal.png')\n",
    "A_axis_a.imshow(sketch_pyramidal, interpolation=\"nearest\")\n",
    "nb.hide_axis_border(axis=A_axis_a)\n",
    "\n",
    "# Figure 1A\n",
    "# Lazy load the data as a NWB file.\n",
    "input_NWBfile = simulations_dir.joinpath('excitatory_validation.nwb')\n",
    "nwbfile = NWBHDF5IO(str(input_NWBfile), 'r').read()\n",
    "per_trial_activity = {}\n",
    "per_trial_activity['soma_NMDA+AMPA'] = analysis.separate_trials(\n",
    "    input_NWBfile=nwbfile, acquisition_name='normal_NMDA+AMPA'\n",
    ")\n",
    "per_trial_activity['dend_NMDA+AMPA'] = analysis.separate_trials(\n",
    "    input_NWBfile=nwbfile, acquisition_name='vdend_normal_NMDA+AMPA'\n",
    ")\n",
    "\n",
    "#TODO: why my data seems to be x4 times? This is also in the previous,somatic\n",
    "# data that I have plotted successfully.. It seems to be a problem with the\n",
    "# NWB file creation.\n",
    "soma_amplitude = [\n",
    "    trace[0][500:5000].max() - trace[0][400]\n",
    "    for trace in per_trial_activity['soma_NMDA+AMPA']\n",
    "]\n",
    "dend_amplitude = [\n",
    "    trace[0][500:5000].max() - trace[0][400]\n",
    "    for trace in per_trial_activity['dend_NMDA+AMPA']\n",
    "]\n",
    "A_axis_b.plot(soma_amplitude[:5], color='C0')\n",
    "A_axis_b.plot(dend_amplitude[:5], color='C1')\n",
    "A_axis_b.set_xlabel(\n",
    "    'Stimulus intensity', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "A_axis_b.set_ylabel(\n",
    "    'Amplitude (mV)', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "nb.axis_normal_plot(axis=A_axis_b)\n",
    "nb.adjust_spines(A_axis_b, ['left', 'bottom'])\n",
    "\n",
    "#TODO: Keep only the structured PLUS input vectors to show the simulation protocol.\n",
    "#sketch_structured = plt.imread('Clustered_network_sketch.png')\n",
    "#A_axis_b.imshow(sketch_structured, interpolation=\"nearest\")\n",
    "#nb.hide_axis_border(axis=A_axis_b)\n",
    "#nb.mark_figure_letter(A_axis_b, 'b')\n",
    "\n",
    "\n",
    "# Figure C\n",
    "# Load a NWB file containing membrane potential:\n",
    "#TODO: remove with interpolation the extra steps per ms of membrane potential\n",
    "# in order to reduce NWB file size.\n",
    "NWBfile = analysis.load_nwb_file(\n",
    "    animal_model=1,\n",
    "    learning_condition=1,\n",
    "    experiment_config='structured',\n",
    "    type='mp',\n",
    "    data_path=glia_dir\n",
    "    #type='bn',\n",
    "    #data_path=simulations_dir\n",
    ")\n",
    "\n",
    "pyramidal_axes = [C_axis_a, C_axis_b, C_axis_c]\n",
    "interneuron_axes = [C_axis_d, C_axis_e, C_axis_f]\n",
    "exemplar_pyramidal_ids = [1, 6, 17]\n",
    "exemplar_interneurons_ids = [252, 257, 268]\n",
    "for id, axis_obj in zip(exemplar_pyramidal_ids, pyramidal_axes):\n",
    "    vsoma = analysis.get_acquisition_potential(\n",
    "        NWBfile=NWBfile, cellid=id, trialid=7\n",
    "    )\n",
    "    axis_obj.plot(vsoma, color='k')\n",
    "    axis_obj.axvspan(50.0, 1050.0, ymin=0, ymax=1, color='g', alpha=0.2)\n",
    "    nb.hide_axis_border(axis=axis_obj)\n",
    "\n",
    "for id, axis_obj in zip(exemplar_interneurons_ids, interneuron_axes):\n",
    "    vsoma = analysis.get_acquisition_potential(\n",
    "        NWBfile=NWBfile, cellid=id, trialid=7\n",
    "    )\n",
    "    axis_obj.plot(vsoma, color='k')\n",
    "    axis_obj.axvspan(50.0, 1050.0, ymin=0, ymax=1, color='g', alpha=0.2)\n",
    "    nb.hide_axis_border(axis=axis_obj)\n",
    "\n",
    "nb.mark_figure_letter(C_axis_a, 'c')\n",
    "\n",
    "#nb.set_horizontal_scalebar(\n",
    "#    axis=C_axis_f,\n",
    "#    label='1 second',\n",
    "#    relativesize=1000,\n",
    "#    distfromy=0.01,\n",
    "#    distfromx=0.4\n",
    "#)\n",
    "\n",
    "\n",
    "stim_ISI_all = []\n",
    "stim_ISI_CV_all = []\n",
    "delay_ISI_all = []\n",
    "delay_ISI_CV_all = []\n",
    "for animal_model in range(1, no_of_animals + 1):\n",
    "    for learning_condition in range(1, no_of_conditions + 1):\n",
    "        NWBfile = analysis.load_nwb_file(\n",
    "            animal_model=animal_model,\n",
    "            learning_condition=learning_condition,\n",
    "            experiment_config='structured',\n",
    "            type='bn',\n",
    "            data_path=simulations_dir\n",
    "        )\n",
    "        # Calculate ISI and its CV:\n",
    "        stim_ISIs, stim_ISIs_CV = analysis.calculate_stimulus_isi(NWBfile)\n",
    "        delay_ISIs, delay_ISIs_CV = analysis.calculate_delay_isi(NWBfile)\n",
    "\n",
    "        stim_ISI_all.append(stim_ISIs)\n",
    "        stim_ISI_CV_all.append(stim_ISIs_CV)\n",
    "        delay_ISI_all.append(delay_ISIs)\n",
    "        delay_ISI_CV_all.append(delay_ISIs_CV)\n",
    "\n",
    "stim_ISI = list(chain(*stim_ISI_all))\n",
    "delay_ISI = list(chain(*delay_ISI_all))\n",
    "stim_ISI_CV = list(chain(*stim_ISI_CV_all))\n",
    "delay_ISI_CV = list(chain(*delay_ISI_CV_all))\n",
    "step_isi = 20\n",
    "step_cv = 0.2\n",
    "bins_isi = np.arange(0, 200, step_isi)\n",
    "bins_cv = np.arange(0, 2, step_cv)\n",
    "# Histograms can contain less values, if original mats have NaNs!\n",
    "stim_isi_hist, *_ = np.histogram(stim_ISI, bins=bins_isi)\n",
    "delay_isi_hist, *_ = np.histogram(delay_ISI, bins=bins_isi)\n",
    "stim_isi_cv_hist, *_ = np.histogram(stim_ISI_CV, bins=bins_cv)\n",
    "delay_isi_cv_hist, *_ = np.histogram(delay_ISI_CV, bins=bins_cv)\n",
    "\n",
    "# Do Kruskar Wallis test on distributions:\n",
    "kruskal_result_cv = stats.kruskal(stim_ISI_CV, delay_ISI_CV, nan_policy='omit')\n",
    "kruskal_result_isi = stats.kruskal(stim_ISI, delay_ISI, nan_policy='omit')\n",
    "\n",
    "average_stim_isi = np.mean(stim_ISI)\n",
    "average_delay_isi = np.mean(delay_ISI)\n",
    "average_stim_cv = np.nanmean(stim_ISI_CV)\n",
    "average_delay_cv = np.nanmean(delay_ISI_CV)\n",
    "\n",
    "std_stim_isi = np.std(stim_ISI)\n",
    "std_delay_isi = np.std(delay_ISI)\n",
    "std_stim_cv = np.nanstd(stim_ISI_CV)\n",
    "std_delay_cv = np.nanstd(delay_ISI_CV)\n",
    "\n",
    "D_axis_a.plot(stim_isi_hist / stim_isi_hist.sum(), color='C0')\n",
    "D_axis_a.axvline(np.mean(stim_ISI) / step_isi, color='C0', linestyle='--')\n",
    "D_axis_a.plot(delay_isi_hist / delay_isi_hist.sum(), color='C1')\n",
    "D_axis_a.axvline(np.mean(delay_ISI) / step_isi, color='C1', linestyle='--')\n",
    "D_axis_a.set_xticks(range(0, bins_isi.size, 2))\n",
    "D_axis_a.set_xticklabels(np.round(bins_isi * 2, 1), fontsize=tick_label_font_size)\n",
    "D_axis_a.set_xlim([0.0, bins_isi.size])\n",
    "D_axis_a.set_xlabel(\n",
    "    'ISI length (ms)', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "D_axis_a.set_ylabel(\n",
    "    'Relative Frequency', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "nb.axis_normal_plot(axis=D_axis_a)\n",
    "nb.adjust_spines(D_axis_a, ['left', 'bottom'])\n",
    "#TODO: Why I have nans inside CV?\n",
    "D_axis_b.plot(stim_isi_cv_hist / stim_isi_cv_hist.sum(), color='C0')\n",
    "D_axis_b.axvline(np.nanmean(stim_ISI_CV) / step_cv, color='C0', linestyle='--')\n",
    "D_axis_b.plot(delay_isi_cv_hist / delay_isi_cv_hist.sum(), color='C1')\n",
    "D_axis_b.axvline(np.nanmean(delay_ISI_CV) / step_cv, color='C1', linestyle='--')\n",
    "D_axis_b.set_xticks(range(0, bins_cv.size, 2))\n",
    "D_axis_b.set_xticklabels(np.round(bins_cv * 2, 1), fontsize=tick_label_font_size)\n",
    "D_axis_b.set_xlim([0.0, bins_cv.size])\n",
    "D_axis_b.set_xlabel(\n",
    "    'Coefficient of Variation', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "D_axis_b.set_ylabel(\n",
    "    'Relative Frequency', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "nb.axis_normal_plot(axis=D_axis_b)\n",
    "nb.adjust_spines(D_axis_b, ['left', 'bottom'])\n",
    "nb.mark_figure_letter(D_axis_a, 'd')\n",
    "\n",
    "\n",
    "\n",
    "# Figure Ea\n",
    "#TODO bale to idio animal me to Fig H1.\n",
    "#TODO: opws einai to NWBfile einai ena tyxaio apo to loop pio panw!\n",
    "# Exemplar network rasterplot:\n",
    "# Trials that have pa: 2, 6. The 6 is quite nice!\n",
    "fig_1e_trial_id = 6\n",
    "nb.plot_trial_spiketrains(\n",
    "    NWBfile=NWBfile, trialid=fig_1e_trial_id, plot_axis=E_axis_a,\n",
    "    axis_label_font_size=axis_label_font_size,\n",
    "    tick_label_font_size=tick_label_font_size,\n",
    "    labelpad_x=labelpad_x, labelpad_y=labelpad_y\n",
    ")\n",
    "\n",
    "#TODO: blah\n",
    "TR_sp = analysis.sparsness(NWBfile)\n",
    "nb.report_value(f'Fig 1E: Sparsness', TR_sp)\n",
    "\n",
    "\n",
    "trial_len = \\\n",
    "    analysis.get_acquisition_parameters(\n",
    "        input_NWBfile=NWBfile,\n",
    "        requested_parameters=[\n",
    "            'trial_len'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Dynamic network response:\n",
    "ff_threshold = 10  # Hz\n",
    "\n",
    "correct_trials = analysis.get_correct_trials(NWBfile)\n",
    "for cellid in range(correct_trials.shape[0]):\n",
    "    smoothed_firing_frequency = \\\n",
    "        savgol_filter(\n",
    "            np.multiply(correct_trials[cellid, fig_1e_trial_id, :].T, 20),\n",
    "            11, 3\n",
    "        )\n",
    "    if smoothed_firing_frequency.mean() > ff_threshold:\n",
    "        # Remove the negative values made from smoothing:\n",
    "        idx = smoothed_firing_frequency < 0\n",
    "        smoothed_firing_frequency[idx] = 0\n",
    "        E_axis_b.plot(smoothed_firing_frequency)\n",
    "\n",
    "\n",
    "#E_axis_b.spines['left'].set_position('zero')\n",
    "#E_axis_b.spines['bottom'].set_position('zero')\n",
    "duration = correct_trials.shape[2]\n",
    "time_axis_ticks = np.linspace(0, duration, (duration / 20) + 1)\n",
    "time_axis_ticklabels = analysis.q2sec(q_time=time_axis_ticks).astype(int)  #np.linspace(0, time_axis_limits[1], duration)\n",
    "E_axis_b.set_xticks(time_axis_ticks)\n",
    "E_axis_b.set_xticklabels(time_axis_ticklabels, fontsize=tick_label_font_size)\n",
    "E_axis_b.set_xlim([0.0, duration])\n",
    "E_axis_b.set_ylim([0.0, 130])\n",
    "E_axis_b.axvspan(50.0/50, 1050.0/50, ymin=0, ymax=120/130, color='g', alpha=0.2)\n",
    "nb.adjust_spines(E_axis_b, ['left', 'bottom'])\n",
    "E_axis_b.set_xlabel(\n",
    "    'Time (ms)', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "E_axis_b.set_ylabel(\n",
    "    'Firing Frequency (Hz)', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "nb.axis_normal_plot(axis=E_axis_b)\n",
    "nb.adjust_spines(E_axis_b, ['left', 'bottom'])\n",
    "nb.mark_figure_letter(E_axis_a, 'e')\n",
    "\n",
    "\n",
    "\n",
    "# Figure G:\n",
    "# Use the same file for the PCA 3d also:\n",
    "NWBfile = analysis.load_nwb_file(\n",
    "    animal_model=1,\n",
    "    learning_condition=2,\n",
    "    experiment_config='structured',\n",
    "    type='bn',\n",
    "    data_path=simulations_dir\n",
    ")\n",
    "trial_len, pn_no, ntrials, trial_q_no = analysis.get_acquisition_parameters(\n",
    "    input_NWBfile=NWBfile,\n",
    "    requested_parameters=['trial_len', 'pn_no', 'ntrials', 'trial_q_no']\n",
    ")\n",
    "custom_range = (0, int(trial_len / 50))\n",
    "\n",
    "# Plot velocity from raw network activity:\n",
    "#TODO: all the data and how many Ls in PCA? Must be all!\n",
    "# Filter only trials with PA\n",
    "net_activity = analysis.get_correct_trials(NWBfile)\n",
    "# This is Hz/Sec.\n",
    "energy = analysis.energy(data=net_activity)\n",
    "G_axis_a.cla()\n",
    "G_axis_a.plot(energy.T, color='gray', alpha=0.2)\n",
    "tmp = np.mean(energy.T, axis=1)\n",
    "G_axis_a.plot(tmp[1:], color='k', linewidth=2)\n",
    "duration = net_activity.shape[2]\n",
    "time_axis_ticks = np.linspace(0, duration, (duration / 20) + 1)\n",
    "time_axis_ticklabels = analysis.q2sec(q_time=time_axis_ticks).astype(int)  #np.linspace(0, time_axis_limits[1], duration)\n",
    "G_axis_a.set_xticks(time_axis_ticks)\n",
    "G_axis_a.set_xticklabels(time_axis_ticklabels, fontsize=tick_label_font_size)\n",
    "G_axis_a.set_ylabel(\n",
    "    'Energy Velocity (Hz/s)', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "G_axis_a.set_xlabel(\n",
    "    'Time (ms)', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "#TODO: use proper values, not hardcoded!\n",
    "G_axis_a.axvspan(50.0 / 50, 1050.0 /50 , ymin=0, ymax=1, color='g', alpha=0.2)\n",
    "nb.axis_normal_plot(axis=G_axis_a)\n",
    "nb.adjust_spines(G_axis_a, ['left', 'bottom'])\n",
    "nb.mark_figure_letter(G_axis_a, 'g')\n",
    "\n",
    "# Figure 1I:\n",
    "velocity = analysis.velocity(data=net_activity)\n",
    "H_axis_a.cla()\n",
    "H_axis_a.plot(velocity.T, color='gray', alpha=0.2)\n",
    "H_axis_a.plot(np.mean(velocity.T, axis=1), color='k', linewidth=2)\n",
    "H_axis_a.set_xticks(time_axis_ticks)\n",
    "H_axis_a.set_xticklabels(time_axis_ticklabels, fontsize=tick_label_font_size)\n",
    "H_axis_a.set_ylabel(\n",
    "    'Multidimensional Velocity (Hz/s)', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "H_axis_a.set_xlabel(\n",
    "    'Time (ms)', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "#TODO: use proper values, not hardcoded!\n",
    "H_axis_a.axvspan(50.0 / 50, 1050.0 /50 , ymin=0, ymax=1, color='g', alpha=0.2)\n",
    "nb.axis_normal_plot(axis=H_axis_a)\n",
    "nb.adjust_spines(H_axis_a, ['left', 'bottom'])\n",
    "nb.mark_figure_letter(H_axis_a, 'h')\n",
    "\n",
    "# Figure 1F:\n",
    "# Load binned acquisition (all trials together)\n",
    "binned_network_activity = NWBfile.acquisition['binned_activity'] \\\n",
    "                              .data[:pn_no, :] \\\n",
    "    .reshape(pn_no, ntrials, trial_q_no)\n",
    "\n",
    "# Perform correlation in each time bin state:\n",
    "#TODO: giati ta trials einai 9 (pou shmainei oti anixneftikan only PA ones),\n",
    "# alla to trial 0 den exei PA?\n",
    "single_trial_activity = binned_network_activity[\n",
    "                        :pn_no, 7, custom_range[0]:custom_range[1]\n",
    "                        ]\n",
    "duration = single_trial_activity.shape[1]\n",
    "timelag_corr = np.zeros((duration, duration))\n",
    "for ii in range(duration):\n",
    "    for jj in range(duration):\n",
    "        S = np.corrcoef(\n",
    "            single_trial_activity[:, ii],\n",
    "            single_trial_activity[:, jj]\n",
    "        )\n",
    "        timelag_corr[ii, jj] = S[0, 1]\n",
    "\n",
    "#figure1, plot_axes = plt.subplots()\n",
    "im = F_axis_a.imshow(timelag_corr, vmin=0.7)\n",
    "F_axis_a.xaxis.tick_top()\n",
    "for axis in ['top', 'bottom', 'left', 'right']:\n",
    "    F_axis_a.spines[axis].set_linewidth(2)\n",
    "F_axis_a.xaxis.set_tick_params(width=2)\n",
    "F_axis_a.yaxis.set_tick_params(width=2)\n",
    "time_axis_limits = (0, duration)\n",
    "#TODO: change the 20 with a proper variable (do I have one?)\n",
    "time_axis_ticks = np.linspace(0, duration, (duration / 20) + 1)\n",
    "time_axis_ticklabels = analysis.q2sec(q_time=time_axis_ticks).astype(int)  #np.linspace(0, time_axis_limits[1], duration)\n",
    "F_axis_a.set_xticks(time_axis_ticks)\n",
    "F_axis_a.set_xticklabels(time_axis_ticklabels, fontsize=tick_label_font_size)\n",
    "F_axis_a.set_yticks(time_axis_ticks)\n",
    "F_axis_a.set_yticklabels(time_axis_ticklabels, fontsize=tick_label_font_size)\n",
    "F_axis_a.set_ylabel(\n",
    "    'Time (s)', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_y\n",
    ")\n",
    "#F_axis_a.set_xlabel('')\n",
    "# create an axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "divider = make_axes_locatable(F_axis_a)\n",
    "cax = divider.append_axes('bottom', size='5%', pad=0.05)\n",
    "figure1.colorbar(im, orientation='horizontal', fraction=0.05,\n",
    "                 cax=cax)\n",
    "cax.set_xlabel(\n",
    "    'Correlation', fontsize=axis_label_font_size,\n",
    "    labelpad=labelpad_x\n",
    ")\n",
    "nb.mark_figure_letter(F_axis_a, 'f')\n",
    "\n",
    "# Figure 1H:\n",
    "K_star, K_labels, BIC_val, _ = analysis.determine_number_of_clusters(\n",
    "    NWBfile_array=[NWBfile],\n",
    "    max_clusters=no_of_conditions,\n",
    "    custom_range=custom_range\n",
    ")\n",
    "\n",
    "TR_sp = analysis.sparsness(NWBfile, custom_range)\n",
    "nb.report_value('Fig 1H: BIC', BIC_val)\n",
    "nb.report_value('Fig 1H: Sparsness', TR_sp)\n",
    "\n",
    "plt.draw()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure1.savefig('Figure_1_final.pdf')\n",
    "figure1.savefig('Figure_1_final.svg')\n",
    "figure1.savefig('Figure_1_final.png')\n",
    "print('Tutto pronto!')\n",
    "\n",
    "\n",
    "#%%"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
